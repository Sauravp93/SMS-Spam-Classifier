{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\sgpur\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing essential libraries\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "# Importing essential libraries for performing Natural Language Processing on 'SMS Spam Collection' dataset\n",
    "import nltk\n",
    "import re\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5751</td>\n",
       "      <td>spam</td>\n",
       "      <td>SPOT ADMISSIONS FOR FORENSIC SCIENCE, Cardiac ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5752</td>\n",
       "      <td>spam</td>\n",
       "      <td>CBSE Private Exam 2018, Forms are starting for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5753</td>\n",
       "      <td>spam</td>\n",
       "      <td>If you receive offer of lottery winnings or ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5754</td>\n",
       "      <td>spam</td>\n",
       "      <td>Gokul sent you a Blue Packet which expires in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5755</td>\n",
       "      <td>spam</td>\n",
       "      <td>CBSE Private Exam 2018, Forms are starting for...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5756 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5751  spam  SPOT ADMISSIONS FOR FORENSIC SCIENCE, Cardiac ...\n",
       "5752  spam  CBSE Private Exam 2018, Forms are starting for...\n",
       "5753  spam  If you receive offer of lottery winnings or ch...\n",
       "5754  spam  Gokul sent you a Blue Packet which expires in ...\n",
       "5755  spam  CBSE Private Exam 2018, Forms are starting for...\n",
       "\n",
       "[5756 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Loading the dataset\n",
    "df1 = pd.read_csv('SmsData.csv')\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning the messages\n",
    "corpus = []\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,df.shape[0]):\n",
    "\n",
    "  # Cleaning special character from the message\n",
    "  Message = re.sub(pattern='[^a-zA-Z]', repl=' ', string=df.Message[i])\n",
    "\n",
    "  # Converting the entire message into lower case\n",
    "  Message = Message.lower()\n",
    "\n",
    "  # Tokenizing the review by words\n",
    "  words = Message.split()\n",
    "\n",
    "  # Removing the stop words\n",
    "  words = [word for word in words if word not in set(stopwords.words('english'))]\n",
    "\n",
    "  # Stemming the words\n",
    "  words = [ps.stem(word) for word in words]\n",
    "\n",
    "  # Joining the stemmed words\n",
    "  Message = ' '.join(words)\n",
    "\n",
    "  # Building a corpus of messages\n",
    "  corpus.append(Message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the Bag of Words model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features=2500)\n",
    "X = cv.fit_transform(corpus).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting dependent variable from the dataset\n",
    "y = pd.get_dummies(df['Label'])\n",
    "y = y.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pickle file for the CountVectorizer\n",
    "pickle.dump(cv, open('cv-transform.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.3)\n",
    "classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a pickle file for the Multinomial Naive Bayes model\n",
    "filename = 'spam-sms-mnb-model.pkl'\n",
    "pickle.dump(classifier, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
